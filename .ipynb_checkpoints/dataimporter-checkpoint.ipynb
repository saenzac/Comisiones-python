{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas import Series, DataFrame\n",
    "from configparser import SafeConfigParser\n",
    "import codecs\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "class ValidateDataFrame(object):\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def validation(self):\n",
    "        pass\n",
    "    \n",
    "    def exportValidation(self, exportparams):\n",
    "        writer = ExcelWriter(exportparams['xlsxfile'])\n",
    "        exportparams['dataframe'].to_excel(writer, index = False, sheet_name = 'validaciones')\n",
    "        self.display(exportparams)\n",
    "        \n",
    "    def display(self, exportparams):\n",
    "        print('Archivo exportado %s con %s registros' % (exportparams['xlsxfile'], len(exportparams['dataframe'])))\n",
    "    \n",
    "class ValidateInar(ValidateDataFrame):\n",
    "    \n",
    "    def __init__(self, dataframelist):\n",
    "        self.inarbruto = dataframelist['inarbruto']\n",
    "        self.jerarquia = dataframelist['jerarquia']\n",
    "        self.comisionantes = dataframelist['comisionantes']\n",
    "        self.tblempleados = dataframelist['tblempleados']\n",
    "        \n",
    "    def validation(self):      \n",
    "        # Validación de blanks : tipodoc, vendedor, zona, tipodoc\n",
    "        \n",
    "        nocolsjerarquia = ['nombre_vendedor','estado_vendedor','gerencia_1','gerencia_2','canal_de_venta','zona_de_venta',\n",
    "                            'supervision_kam','departamento','codigo_inar']\n",
    "        nocolsm2m = ['id_empl', 'codigo_inar', 'dni', 'apellido_paterno', 'nombres', 'apellido_materno', 'fecha_ingreso', \n",
    "                    'fecha_actualizacion', 'posicion_empl', 'periodo_activacion']\n",
    "        \n",
    "        # Limpiando el inar bruto\n",
    "        df0 = self.inarbruto[self.inarbruto['estado'] != 'DEAC']\n",
    "        df0 = df0[df0['vendedor']!= 'SERVICIO_GENERAL1']      \n",
    "        \n",
    "        #Corrige las Ñs\n",
    "        df0 = df0.replace(',|\\r|\"|\\x91', '', regex = True)\n",
    "        df0[['vendedor','razon_social']] = df0[['vendedor','razon_social']].replace('Ã','Ñ', regex = True)\n",
    "              \n",
    "        # Empezando con las validaciones    \n",
    "        blanksdoc = df0[(df0['tipodoc'].isnull()) & (~df0['plan_tarifario'].str.contains('Prepago'))]\n",
    "        blanksdoc['observacion'] = 'blanks en documento'\n",
    "        \n",
    "        df0 = df0[df0['tipodoc'].isin(['RUC',np.NaN])]\n",
    "        \n",
    "        blanksvendedor = df0[(df0['vendedor'].isnull()) | (df0['zona'].isnull())]\n",
    "        blanksvendedor['observacion'] = 'blanks en vendedor o zona'\n",
    "        \n",
    "        vendedorsinjerarquia = df0.merge(self.jerarquia.drop_duplicates(['codigo_inar']),left_on = ['vendedor'], \n",
    "                                        right_on = ['codigo_inar'], how = 'left' )\n",
    "        vendedorsinjerarquia = vendedorsinjerarquia[vendedorsinjerarquia['gerencia_2'].isnull()]   \n",
    "        vendedorsinjerarquia.drop(nocolsjerarquia, inplace=True, axis=1)    \n",
    "        vendedorsinjerarquia['observacion'] = 'vendedor no se encuentra en jerarquia de ventas'\n",
    "        \n",
    "        # Detectando planes de data con consultores de voz\n",
    "        \n",
    "        emplactivos = self.tblempleados[self.tblempleados['fecha_cese'] == '']\n",
    "        \n",
    "        puestosvoz = emplactivos[~emplactivos['posicion_empl'].\n",
    "                                 str.contains('Soluciones de Negocio')]['posicion_empl'].drop_duplicates()\n",
    "        puestosvoz = puestosvoz.tolist()\n",
    "        \n",
    "        vozm2m = df0.merge(emplactivos, left_on = ['vendedor'], right_on = ['codigo_inar'], how = 'left' )\n",
    "        vozm2m = vozm2m[vozm2m['plan_tarifario'].str.contains('M2M') & vozm2m['posicion_empl'].isin(puestosvoz)]\n",
    "        vozm2m.drop(nocolsm2m, inplace = True, axis = 1)\n",
    "        vozm2m['observacion'] = 'consultor de voz con planes data'\n",
    "        \n",
    "        # Detectando empleados inactivos\n",
    "        emplcesados = self.tblempleados[self.tblempleados['fecha_cese'] != '']\n",
    "        inactivos = df0.merge(emplcesados, left_on = ['vendedor'], right_on = ['codigo_inar'])\n",
    "        inactivos.drop(nocolsm2m, inplace = True, axis = 1)\n",
    "        inactivos['observacion'] = 'consultor cesado'\n",
    "        \n",
    "        df = blanksdoc.append(blanksvendedor, ignore_index = True)\n",
    "        df = df.append(vendedorsinjerarquia, ignore_index = True)\n",
    "        df = df.append(vozm2m, ignore_index = True)\n",
    "        df = df.append(inactivos, ignore_index = True)\n",
    "        \n",
    "        df = df [['codigo','razon_social','contrato','fec_activ','fec_desactiva','estado','telefono','modelo','tmcode',\n",
    "                  'plan_tarifario','vendedor','zona','dealer','tecnologia','tipodoc','documento','falso_deac','fecha_proceso',\n",
    "                  'fecha_cese','observacion']]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "class ValidateMultipleData(ValidateDataFrame):\n",
    "    \n",
    "    def __init__(self, dataframelist):\n",
    "\n",
    "        self.jerarquia = dataframelist['jerarquia']\n",
    "        self.comisionantes = dataframelist['comisionantes']\n",
    "        self.tblempleados = dataframelist['tblempleados']\n",
    "        \n",
    "    def validation(self):      \n",
    "        \n",
    "       \n",
    "        tblempleados = self.tblempleados[['codigo_inar', 'fecha_cese', 'posicion_empl']]\n",
    "        comisionantes = self.comisionantes[['login', 'gerencia2', 'zona', 'departamento', 'posición']]\n",
    "        jerarquia = self.jerarquia[['canal_vista_negocio', 'gerencia_2', 'zona_de_venta', 'departamento', 'vendedor', \n",
    "                                    'estado_vendedor']]\n",
    "        \n",
    "        # Observaciones en jerarquia\n",
    "        \n",
    "        gerencia2 = ['CORPORACIONES','DESARROLLO NEGOCIOS PYME','GRANDES CLIENTES','SOLUCIONES DE DATOS',\n",
    "                     'VD PYMES','VENTA REGIONAL EMPRESA']\n",
    "        jerarquiadep = jerarquia[(jerarquia['canal_vista_negocio'] == 'EJECUTIVO ENTEL') & \n",
    "                                 (jerarquia['estado_vendedor'] == 'Activo')]\n",
    "        jerarquiadep = jerarquiadep[jerarquiadep['gerencia_2'].isin(gerencia2)]\n",
    "        \n",
    "        emplcesados = tblempleados[(tblempleados['codigo_inar'] != '') & (tblempleados['fecha_cese'] != '')]\n",
    "        \n",
    "        vendedorinactivo = jerarquiadep.merge(emplcesados, left_on=['vendedor'],right_on=['codigo_inar'])\n",
    "        vendedorinactivo['observacion'] = 'inactivar vendedor en jerarquia'\n",
    "        vendedorinactivo.drop(['vendedor'], axis = 1, inplace =True)\n",
    "             \n",
    "        # Observaciones en comisionantes\n",
    "        \n",
    "        comisionantespos = comisionantes[comisionantes['posición'].str.contains('Consultor|Ejecutivo')]\n",
    "        colscomisionantes = ['login','gerencia2','zona','departamento']\n",
    "        concomisionantes = comisionantespos[colscomisionantes]\n",
    "        concomisionantes['concolscom'] = concomisionantes.apply(lambda x : '|'.join(x), axis = 1)\n",
    "        \n",
    "        colsjerarquia = ['vendedor','gerencia_2','zona_de_venta','departamento']\n",
    "        conjerarquia = jerarquiadep[colsjerarquia]      \n",
    "        conjerarquia['concolsjer'] = conjerarquia.apply(lambda x : '|'.join(x), axis = 1)\n",
    "            \n",
    "        comparezonas = concomisionantes.merge(conjerarquia, left_on = ['login'], right_on = ['vendedor'], how = 'left')\n",
    "        comparezonas = comparezonas[comparezonas['concolscom'] != comparezonas['concolsjer']]\n",
    "        comparezonas['observacion'] = 'diferencias en zonas'\n",
    "        comparezonas.rename(columns = {'login':'codigo_inar','departamento_x':'departamento'}, inplace = True)\n",
    "        comparezonas.drop(['concolscom', 'concolsjer', 'vendedor'], axis = 1, inplace =True)\n",
    "        \n",
    "        # Observaciones en tblempleados\n",
    "        \n",
    "        tblsincodigos = jerarquiadep.merge(tblempleados, left_on = ['vendedor'], right_on = ['codigo_inar'], how = 'left')\n",
    "        tblsincodigos = tblsincodigos[tblsincodigos['codigo_inar'].isnull()]\n",
    "        tblsincodigos ['observacion'] = 'ingresar el codigo_inar en la tabla empleados'\n",
    "        tblsincodigos['codigo_inar'] = tblsincodigos['vendedor']\n",
    "        \n",
    "        # Observaciones en la posición de comisionantes\n",
    "        errorenpuesto = comisionantes.merge(tblempleados, left_on = ['login'], right_on = ['codigo_inar'])\n",
    "        errorenpuesto = errorenpuesto[errorenpuesto['posición'] != errorenpuesto['posicion_empl']]\n",
    "        errorenpuesto['observacion'] = 'actualizar el puesto en tblempleados'\n",
    "            \n",
    "        # Armando el df con las observaciones\n",
    "        df = vendedorinactivo.append(comparezonas, ignore_index= True)\n",
    "        df = df.append(tblsincodigos, ignore_index = True)\n",
    "        df = df.append(errorenpuesto, ignore_index = True)\n",
    "        df.drop(['canal_vista_negocio', 'estado_vendedor','posicion_empl', 'login', 'vendedor'], axis = 1, inplace =True)\n",
    "        \n",
    "        df = df[['codigo_inar','gerencia2','gerencia_2','zona','zona_de_venta','departamento','departamento_y','posición',\n",
    "                 'fecha_cese','observacion']]\n",
    "\n",
    "        \n",
    "        #df.to_csv(testpath + month + '_otras validaciones.csv')\n",
    "        return df\n",
    "        # Puesto no es el correcto\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "class DbGenericOperator(object):\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def opendb(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def closedb(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def readtbl(self,query):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def writetbl(self,query):\n",
    "        raise NotImplementedError      \n",
    "\n",
    "    @abc.abstractmethod    \n",
    "    def updatetbl(self):\n",
    "        raise NotImplementedError\n",
    "  \n",
    "    @abc.abstractmethod\n",
    "    def deletetbl(self,query):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class DbSqLiteOperator(DbGenericOperator):\n",
    "\n",
    "\n",
    "    def __init__(self, params):\n",
    "\n",
    "        self.dbpath = params['dbpath']\n",
    "        self.dbname = params['dbname']\n",
    "\n",
    "    def openDb(self):\n",
    "        self.conn = sqlite3.connect(self.dbpath + self.dbname, detect_types = sqlite3.PARSE_DECLTYPES)\n",
    "        \n",
    "    def closeDb(self):\n",
    "        self.conn.close()\n",
    "        \n",
    "    def readTbl(self, query):\n",
    "        df = pd.read_sql_query(query, self.conn)\n",
    "        return df\n",
    "     \n",
    "    def writeTbl(self, sql, tuplas):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.executemany(sql, tuplas)\n",
    "        self.conn.commit()\n",
    "        cursor.close()\n",
    "        \n",
    "    def updateTbl(self, sql, args):      \n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.executemany(sql, args)\n",
    "        self.conn.commit()\n",
    "        cursor.close()\n",
    "        \n",
    "    def deleteTbl(self, query):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DbManager(object):\n",
    "    \n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    @abc.abstractmethod \n",
    "    def prepare(self):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod       \n",
    "    def operation(self):\n",
    "        pass\n",
    "  \n",
    "    def display(self, paramstable):\n",
    "        print('Registros de la tabla %s es %s registros ' % ((paramstable['section'], paramstable['lenght'])))\n",
    "    \n",
    "class LoadTbl(DbManager):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        \n",
    "    def prepare(self):\n",
    "        pass\n",
    "    \n",
    "    def operation(self):\n",
    "        \n",
    "        dboperator = DbSqLiteOperator(self.params)\n",
    "        dboperator.openDb()\n",
    "        df = dboperator.readTbl(self.params['query'])\n",
    "        dboperator.closeDb()\n",
    "        df = df.fillna('')\n",
    "        return df\n",
    "\n",
    "class DbDataProcess(object):\n",
    "    \n",
    "    def __init__(self, month):\n",
    "        self.month = month\n",
    "        self.parser = None\n",
    "        self.section = None\n",
    "        self.parameters = None\n",
    "        self.dbpath = 'D:/Datos de Usuario/cleon/Documents/Capital Humano/Bases/'\n",
    "        self.dbname = 'comisiones3.sqlite'\n",
    "        \n",
    "    def configParameters(self): # incluía parser\n",
    "   \n",
    "\n",
    "        l2 = []\n",
    "        \n",
    "        itemlist = ['colstoinsert', 'coldates', 'colstoupdate']\n",
    "    \n",
    "        for item in self.parser.options(self.section): # \n",
    "            if item in itemlist:\n",
    "                l2.append(ast.literal_eval(self.parser.get(self.section,item)))      \n",
    "            else:\n",
    "                l2.append(self.parser.get(self.section,item))\n",
    "\n",
    "        self.parameters = dict(zip(self.parser.options(self.section),l2))\n",
    "\n",
    "        self.parameters['section'] = self.section\n",
    "        self.parameters['dbpath'] = self.dbpath\n",
    "        self.parameters['dbname'] = self.dbname\n",
    "                \n",
    "    \n",
    "    def loadData(self, section):\n",
    "        \n",
    "        self.section = section\n",
    "        self.configParameters()\n",
    "        \n",
    "        dbobj = LoadTbl(self.parameters)\n",
    "        df = dbobj.operation()\n",
    "        df.name = section\n",
    "        \n",
    "        paramstable = {'section' : self.section, 'lenght' : len(df)}\n",
    "        dbobj.display(paramstable)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def setParser(self, parser):\n",
    "        self.parser = parser\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Loader import fileloader as fl\n",
    "\n",
    "month = '201706'\n",
    "testpath = 'D:/Datos de Usuario/cleon/Documents/Capital Humano/Data Fuente Comisiones/test/'\n",
    "defaultpath = 'D:/Datos de Usuario/cleon/Documents/Capital Humano/Data Fuente Comisiones/xlsx/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inifile = fl.ReadIniFile('C:/Anaconda3/MeScripts/Comisiones4/Config/myconfig.ini')\n",
    "parser = inifile.readFile()\n",
    "\n",
    "loader = fl.LoadFileProcess(month)\n",
    "loader.setParser(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de Inar_bruto es 694971 registros\n",
      "El tamaño de Jerarquia es 23212 registros\n",
      "El tamaño de Comisionantes_voz es 352 registros\n",
      "Registros de la tabla tblEmpleados es 755 registros \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1170: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "# Importando la información\n",
    "\n",
    "inarbruto = loader.loadFile('Inar_bruto')\n",
    "jerarquia = loader.loadFile('Jerarquia')\n",
    "comisionantes = loader.loadFile('Comisionantes_voz')\n",
    "\n",
    "inidb = fl.ReadIniFile('C:/Anaconda3/MeScripts/Comisiones4/Config/mydbconfig.ini')\n",
    "dbparser = inidb.readFile()\n",
    "\n",
    "dbmanager = DbDataProcess(month)\n",
    "dbmanager.setParser(dbparser)\n",
    "tblempleados = dbmanager.loadData('tblEmpleados')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado D:/Datos de Usuario/cleon/Documents/Capital Humano/Data Fuente Comisiones/test/201706_validaciones en INAR.xlsx con 1601 registros\n",
      "Archivo exportado D:/Datos de Usuario/cleon/Documents/Capital Humano/Data Fuente Comisiones/test/201706_Otras validaciones.xlsx con 83 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Armando las validaciones\n",
    "\n",
    "valinarfl = {'inarbruto' : inarbruto, 'jerarquia' : jerarquia, 'comisionantes' : comisionantes, 'tblempleados' : tblempleados}\n",
    "valinarobj = ValidateInar(valinarfl)\n",
    "inarvalidation = valinarobj.validation()\n",
    "\n",
    "#importante renombrar la columna codigo_inar en jerarquia\n",
    "jerarquia.rename(columns = {'codigo_inar' : 'vendedor'}, inplace = True)\n",
    "\n",
    "valmultipledatafl = {'jerarquia' : jerarquia, 'comisionantes' : comisionantes, 'tblempleados' : tblempleados}\n",
    "valmultipledataobj = ValidateMultipleData(valmultipledatafl)\n",
    "multipledatavalidation = valmultipledataobj.validation()\n",
    "\n",
    "#****** Exportar validaciones\n",
    "\n",
    "xlsxfile1 = testpath + month + '_validaciones en INAR.xlsx'\n",
    "exportparams = {'xlsxfile' : xlsxfile1, 'dataframe' : inarvalidation}\n",
    "valinarobj.exportValidation(exportparams)\n",
    "\n",
    "xlsxfile2 = testpath + month + '_Otras validaciones.xlsx'\n",
    "exportparams = {'xlsxfile' : xlsxfile2, 'dataframe' : multipledatavalidation}\n",
    "valmultipledataobj.exportValidation(exportparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "login                        object\n",
       "gerencia2                    object\n",
       "zona                         object\n",
       "departamento                 object\n",
       "kam                          object\n",
       "posición                     object\n",
       "nombres                      object\n",
       "dni                         float64\n",
       "fecha_de_planilla    datetime64[ns]\n",
       "fecha_de_ingreso     datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comisionantes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
