{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from Loader import fileloader_proto as fl\n",
    "from Loader import dfutils\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import posixpath\n",
    "\n",
    "logger = logging.getLogger(\"\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "month = '201903'\n",
    "\n",
    "inifile = fl.ReadIniFile(mercado=\"empresas\")\n",
    "#defaultpath = inifile.getDataPath()\n",
    "#testpath = inifile.getTestPath()\n",
    "#parser = inifile.getIniFileParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimiento**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Copiar archivos de comisiones a la carpeta de reporte de productividad\n",
    "- Ejecutar Script para normalizar pesos\n",
    "- En el archivo final de R. Productividad eliminar los cesados y agregar los nuevos.\n",
    "- Ejecutar Script para cuadrar \"reporte de productividad\". Ojo: Este usa el orden de planilla que esta en el reporte final de productividad.\n",
    "- Este ultimo script creara un archivo en testpath, usar ese para copiar y pegar las columnas en el reporte final de productividad\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizar Matriz de Pesos de Comisiones**\n",
    "---\n",
    "\n",
    "Tomamos $A_{mxn}=\\begin{bmatrix}a_{i,j}\\end{bmatrix}$y queremos obtener\n",
    "$\\begin{bmatrix}\\frac{a_{i,j}}{\\sum_{k=1}^{n}a_{i,k}}\\end{bmatrix}_{1xm}$\n",
    "\n",
    "Hallamos el vector suma de las filas:\n",
    "\n",
    "$A_{s}=\\begin{bmatrix}\\sum_{k=1}^{n}a_{i,k}\\end{bmatrix}_{1xm}$\n",
    "\n",
    "Invertimos:\n",
    "\n",
    "$(A_{s}^{-1})_{1xm}$\n",
    "\n",
    "Hallamos la diagonal:\n",
    "\n",
    "\\{$diag(A_{s}^{-1})\\}_{mxm}$\n",
    "\n",
    "Multiplicamos esta matriz diagonal por la matriz inicial para obtener\n",
    "lo buscado:\n",
    "\n",
    "\\{$diag(A_{s}^{-1})\\}_{mxm}*A_{mxn}=T\\{a_{i,j}\\}$\n",
    "\n",
    "$\\begin{bmatrix}*_{1}\\\\\n",
    " & *_{2}\\\\\n",
    " &  & \\ddots\n",
    "\\end{bmatrix}*\\begin{bmatrix}\\Delta_{1,1} & \\Delta_{1,2}\\begin{array}{c}\n",
    "\\cdots\\end{array}\\\\\n",
    "\\Delta_{2,1} & \\Delta_{2,2}\\begin{array}{c}\n",
    "\\cdots\\end{array}\\\\\n",
    "\\vdots & \\vdots\n",
    "\\end{bmatrix}=\\begin{bmatrix}*_{1}\\Delta_{1,1} & *_{1}\\Delta_{1,2}\\begin{array}{c}\n",
    "\\cdots\\end{array}\\\\\n",
    "*_{2}\\Delta_{2,1} & *_{2}\\Delta_{2,2}\\begin{array}{c}\n",
    "\\cdots\\end{array}\\\\\n",
    "\\vdots & \\vdots\n",
    "\\end{bmatrix}=T\\{a_{i,j}\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de Productividad_Pymes es 64 registros\n",
      "El tamaño de Productividad_Pymes es 95 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Johnny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "#Escoger que archivo se desea normalizar los pesos\n",
    "#chosen_file = \"Productividad_Plataformas_Comerciales\"\n",
    "#chosen_file = \"Productividad_Grandes_Cuentas\"\n",
    "#chosen_file = \"Productividad_Soluciones_Negocio\"\n",
    "#chosen_file = \"Productividad_Pymes\"\n",
    "\n",
    "# Dataframe de archivo comisiones pestaña \"Leyenda\" de la ruta de Reporte de Productividad\n",
    "section_1 = fl.SectionObj(inifile,chosen_file,month)\n",
    "section_1.setParameter('presetsheet','Leyenda')\n",
    "loader1 = fl.LoadFileProcess(section_1)\n",
    "pesospltfrs = loader1.loadFile()\n",
    "\n",
    "# Dataframe de archivo comisiones pestaña \"Comisionantes\" de la ruta de Reporte de Productividad\n",
    "section_2 = fl.SectionObj(inifile,chosen_file,month)\n",
    "section_2.setParameter('presetsheet','Comisionantes')\n",
    "loader2 = fl.LoadFileProcess(section_2)\n",
    "comisionantespltfrs = loader2.loadFile()\n",
    "\n",
    "#Obteniendo ruta del archivo de comisiones para ser accedida por XlWings\n",
    "file = section_2.getParameter('filelist')[0]\n",
    "logger.debug(file)\n",
    "\n",
    "#Abriendo archivo de Excel y haciendo hoja 'comisionantes' activa\n",
    "wb = xw.Book(file)\n",
    "comis_sheet = wb.sheets('Comisionantes')\n",
    "leyenda_sheet = wb.sheets('Leyenda')\n",
    "#for sheet in wb.sheets:\n",
    "#  if 'Leyenda' in sheet:\n",
    "#    logger.debug(\"yes\")\n",
    "\n",
    "### Inmovilizando valores de porcentajes ponderados\n",
    "#Obteniendo indice de la columna de porcentaje ponderado\n",
    "ponderado_cindex = dfutils.getExcelColIndexFromDF(comisionantespltfrs, \"PORCENTAJE_TOTAL_PONDERADO\")\n",
    "#Hallando ultima fila de la columna 'PORCENTAJE_TOTAL_PONDERADO'\n",
    "lastrow = comis_sheet.api.Cells(65536, ponderado_cindex).End(xw.constants.Direction.xlUp).Row\n",
    "#Copiando como valores las contenidos de la columna\n",
    "comis_sheet.range((1, ponderado_cindex)).options(transpose=True).value = comis_sheet.range((1, ponderado_cindex), (lastrow,ponderado_cindex)).value\n",
    "\n",
    "# Nombres clave de la hoja leyenda, siempre verificar que esto no cambie, en caso lo haga modificar la siguiente tupla. Porque de lo contrario el algoritmo dara errores / no funcionara como se espera.\n",
    "COMIS_COLUMNS_NAMES = (\"CAPTURA\", \"GESTIÓN\", \"DESARROLLO\", \"ITEM\")\n",
    "\n",
    "### Filtramos la data de la pestaña 'Leyenda' y nos quedamos con la sección de pesos únicamente en el dataframe pesos_df\n",
    "pesos_df = pesospltfrs\n",
    "pesos_df = pesos_df[pesos_df['ITEM'] != COMIS_COLUMNS_NAMES[3]]\n",
    "pesos_df = pesos_df[~pesos_df['ITEM'].isnull()]\n",
    "pesos_df = pesos_df[pesos_df['ITEM'] < 3000]\n",
    "pesos_df = pesos_df[pesos_df['ITEM'] > 2000]\n",
    "\n",
    "mat_result = []\n",
    "\n",
    "for i in range(3):\n",
    "    regexp = COMIS_COLUMNS_NAMES[i] + \".*\"\n",
    "    #Nos quedamos unicamente con las columnas que comienzan con el patron en 'regexp'\n",
    "    area_df = pesos_df.filter(regex=regexp)\n",
    "    #Guardamos las cabeceras\n",
    "    headers = area_df.columns.values\n",
    "    area_df = area_df.fillna(0) #fill empty spaces read as nan to zeros\n",
    "    #Convertimos el dataframe en una matriz numpy (array representation)\n",
    "    area_mat = area_df.as_matrix() #mxn\n",
    "    #Operaciones de matrices\n",
    "    sum_mat_1 = np.sum(area_mat, axis=1) #1xm, sum all the rows\n",
    "    #Invertimos escalarmente el vector\n",
    "    sum_mat_2 = 1 / sum_mat_1\n",
    "    #Reemplazamos los NaN por ceros\n",
    "    sum_mat = np.nan_to_num(sum_mat_2, copy=True)\n",
    "    #Creamos una matriz diagonal, donde los elementos en la diagonal son las sumas de cada fila.\n",
    "    diag_mat = np.diag(sum_mat) #mxm\n",
    "    #Multiplicacion matricial entre la matriz diagonal y la matrix original\n",
    "    t_mat = np.dot(diag_mat, area_mat) #mxm x mxn = mxn\n",
    "    #Resultado buscado\n",
    "    df_conv = pd.DataFrame(t_mat, columns=headers)\n",
    "    mat_result.append(df_conv)\n",
    "\n",
    "df_conv = pd.concat([mat_result[0], mat_result[1], mat_result[2]], axis=1)\n",
    "\n",
    "# Creamos copia de seguridad de la tabla de pesos antes de modificarla.\n",
    "wb.sheets.add('backup_pesos')\n",
    "backup_pesos_sheet = wb.sheets('backup_pesos')\n",
    "backup_pesos_sheet.range('A1').value = pesos_df\n",
    "\n",
    "#Buscar numero de columna CAPTURA 1\n",
    "col_pesos = pesospltfrs.columns.get_loc(COMIS_COLUMNS_NAMES[0] + \"_1\") + 1\n",
    "#Buscar  numero de fila primera ocurrencia de ITEM\n",
    "row_pesos = min(pesospltfrs.index[pesospltfrs['ITEM'] == COMIS_COLUMNS_NAMES[3]].tolist()) + 4\n",
    "# Escribimos los nuevos pesos en el lugar de los antiguos.\n",
    "leyenda_sheet.range(row_pesos, col_pesos).options(pd.DataFrame, index=False).value = df_conv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cuadrar Reporte Productividad**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de Productividad_Final es 450 registros\n",
      "El tamaño de Padron_Empleados es 2819 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de Productividad_All_Files es 451 registros\n"
     ]
    }
   ],
   "source": [
    "# Cargar Data Frame de DNIs de los comisionantes del Reporte de Productividad Final\n",
    "section_3 = fl.SectionObj(inifile,\"Productividad_Final\")\n",
    "loader3 = fl.LoadFileProcess(section_3)\n",
    "dnis_rp = loader3.loadFile()\n",
    "\n",
    "section_4 = fl.SectionObj(inifile,\"Padron_Empleados\",month)\n",
    "loader4 = fl.LoadFileProcess(section_4)\n",
    "empleados_df = loader4.loadFile()\n",
    "empleados_df = empleados_df[[\"DNI\",\"JEFE_DIRECTO\"]]\n",
    "\n",
    "# Cargar Dataframe de archivos de pesos comisiones\n",
    "section_5 = fl.SectionObj(inifile,\"Productividad_All_Files\",month)\n",
    "loader5 = fl.LoadFileProcess(section_5)\n",
    "planilla_comis= loader5.loadFile()\n",
    "planilla_comis = planilla_comis[[\"GERENCIA2\",\"DNI\",\"NOMBRES\",\"POSICIÓN\",\"FECHA_DE_INGRESO\",\"PORCENTAJE_TOTAL_PONDERADO\",\"FACTOR_DE_PAGO\",\"CAPTURA\",\"GESTIÓN\",\"DESARROLLO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamos con DNI del archivo de R. Productividad final\n",
    "df1 = pd.merge(dnis_rp, planilla_comis, on='DNI', how='left')\n",
    "# Cruzamos con Ingresos para obtener el JEFE DIRECTO.\n",
    "df2 = pd.merge(df1, empleados_df, on='DNI', how='left')\n",
    "#Eliminamos duplicados, pueden darse porque ftocci por ejemplo\n",
    "df2.drop_duplicates('DNI')\n",
    "#Establecemos el orden de columnas de salida\n",
    "df2 = df2[[\"GERENCIA2\",\"DNI\",\"NOMBRES\",\"POSICIÓN\",\"FECHA_DE_INGRESO\",\"JEFE_DIRECTO\",\"PORCENTAJE_TOTAL_PONDERADO\",\"FACTOR_DE_PAGO\",\"CAPTURA\",\"GESTIÓN\",\"DESARROLLO\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataoutdir = inifile.getTestPath()\n",
    "writer = pd.ExcelWriter(posixpath.join(dataoutdir,month + \"_ReporteProdutividad.xlsx\"), engine='xlsxwriter')\n",
    "df2.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
